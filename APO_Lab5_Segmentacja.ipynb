{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXAve7azp2Qy"
   },
   "source": [
    "# APO Lab 5 Segmentacja obrazu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 637,
     "status": "ok",
     "timestamp": 1620675268814,
     "user": {
      "displayName": "Łukasz Roszkowiak",
      "photoUrl": "",
      "userId": "11129872457337404255"
     },
     "user_tz": -120
    },
    "id": "c9v3DebgjLgI"
   },
   "outputs": [],
   "source": [
    "#from google.colab.patches import cv2_imshow\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7AthW3AVYw4"
   },
   "source": [
    "!WAŻNE! Aby poniższy plik działał na Google Colab, należy wgrać plik 'lena_gray.bmp' oraz 'water_coins.jpg'. Z panelu po lewej stronie wybieramy ikonę folderu ('Files') a następnie 'Upload' i wybieramy zdjęcie (wcześniej ściągnięte na dysk twardy z UBI)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhiwTnFcLXMl"
   },
   "source": [
    "# Zadanie 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "executionInfo": {
     "elapsed": 1670,
     "status": "ok",
     "timestamp": 1620675269895,
     "user": {
      "displayName": "Łukasz Roszkowiak",
      "photoUrl": "",
      "userId": "11129872457337404255"
     },
     "user_tz": -120
    },
    "id": "OfYoPimSjPaX",
    "outputId": "fa0fd8ef-801e-4945-b8c7-05730c97a34f"
   },
   "outputs": [],
   "source": [
    "# Wczytanie obrazu pierwotnego\n",
    "img = cv2.imread('lena_gray.bmp', cv2.IMREAD_GRAYSCALE)\n",
    "#img = cv2.imread('page.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "#cv2_imshow(img)\n",
    "#plt.figure(figsize=(10,10))\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MyLze_e9LPM5"
   },
   "source": [
    "## Zad 1. a) Segmentacja obrazu przez progowanie z ręcznie wyznaczonym progiem (thresholding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KZ1H6iAIeix"
   },
   "source": [
    "\n",
    "Algorytm progowania realizuje prostą zależność gdzie wartości powyżej ustalonego progu przyjmują wartośc 1 (lub 255) a wartości poniżej wartość 0. \n",
    "\n",
    "![alt text](https://github.com/knave88/APO/raw/main/progowanie.png)\n",
    "\n",
    "W efekcie otrzymujemy binarny obraz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "executionInfo": {
     "elapsed": 1652,
     "status": "ok",
     "timestamp": 1620675269897,
     "user": {
      "displayName": "Łukasz Roszkowiak",
      "photoUrl": "",
      "userId": "11129872457337404255"
     },
     "user_tz": -120
    },
    "id": "TanGLU-RmSvG",
    "outputId": "c09b8cc4-2ba0-4ec3-82ed-fa722590c77d"
   },
   "outputs": [],
   "source": [
    "# ręczne ustawienie progu \n",
    "myThresh = 127\n",
    "# progowanie z powyższyą wartością progu\n",
    "ret,img_th_binary = cv2.threshold(img,myThresh,255,cv2.THRESH_BINARY)\n",
    "\n",
    "#cv2_imshow(img_th_binary)\n",
    "#plt.figure(figsize=(10,10))\n",
    "plt.imshow(img_th_binary, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6a-n_NBgZ-R"
   },
   "source": [
    "W programie zaliczenowym należy dać możliwość użytkownikowi interaktywnego doboru progu (najlepiej z aktywnym podglądem, czyli odświeżaniem obrazu po zmianie wartości progu). Przyład implementacji poniżej z zastosowaniem suwaka (slider) do przyjęcia wartości progu od użytkowanika."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "def fun_thresh(slider_threshold_value):\n",
    "    print(\"Wybrana wastość progu: \" + str(slider_threshold_value))\n",
    "    \n",
    "    # progowanie z powyższyą wartością progu\n",
    "    ret,img_th_binary2 = cv2.threshold(img,slider_threshold_value,255,cv2.THRESH_BINARY)\n",
    "    \n",
    "    #cv2_imshow(img_th_binary2)\n",
    "    #plt.figure(figsize=(10,10))\n",
    "    plt.imshow(cv2.cvtColor(img_th_binary2, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    return slider_threshold_value\n",
    "\n",
    "#interact(fun_thresh, slider_threshold_value=58); # widgets.IntSlider(min=-10, max=30, step=1, value=10)\n",
    "interact(fun_thresh, slider_threshold_value=widgets.IntSlider(min=0, max=255, step=1, value=127));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CbKaaK_aLjDY"
   },
   "source": [
    "## Zad 1. b) Segmentacja obrazu przez progowanie adaptacyjne (adaptive thresholding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfUYyyLqMEZR"
   },
   "source": [
    "Funkcja progowania adaptacyjnego wykonuje lokalne progowanie, dla każdego piksela jest wyznaczany próg na podstawie obszaru otaczającego analizowany piksel, zgodnie ze schematem okna przesuwnego. \n",
    "\n",
    "W bibliotece openCV aby użyć funkcji cv2.adaptiveThreshold należy podać jako parametry wejściowe:\n",
    "*   obraz wejściowy (img)\n",
    "*   maksymalną wartość dla obrazu (255)\n",
    "*   sposób liczenia progu (adaptive_method = cv2.ADAPTIVE_THRESH_MEAN_C) na podstawie wartości średniej, lub (ADAPTIVE_THRESH_GAUSSIAN_C) średniej ważonej \n",
    "*   progowanie wprost (threshold_type = cv2.THRESH_BINARY), lub (THRESH_BINARY_INV) z inwersją\n",
    "*   rozmiar okna poddawanego analizie, powinno mieć wartość nieprzystą (block_size = 11)\n",
    "*   stała wartość odejmowana od średniej (5)\n",
    "\n",
    "Poniżej przedstawiono dwie wersje liczenia progu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "executionInfo": {
     "elapsed": 3077,
     "status": "ok",
     "timestamp": 1620675271364,
     "user": {
      "displayName": "Łukasz Roszkowiak",
      "photoUrl": "",
      "userId": "11129872457337404255"
     },
     "user_tz": -120
    },
    "id": "sKmwB_xrGi7R",
    "outputId": "dce01572-e046-4b48-d8b2-8f42dfd65f9e"
   },
   "outputs": [],
   "source": [
    "\n",
    "max_value = 255\n",
    "adaptive_method = cv2.ADAPTIVE_THRESH_MEAN_C\n",
    "threshold_type = cv2.THRESH_BINARY\n",
    "block_size = 11\n",
    "\n",
    "# progowanie z powyższyą wartością progu\n",
    "img_th_adapt = cv2.adaptiveThreshold(img, max_value, adaptive_method, threshold_type, block_size, 5)\n",
    "\n",
    "#cv2_imshow(img_th_binary)\n",
    "frame = cv2.hconcat((img, img_th_adapt))\n",
    "#plt.figure(figsize=(10,10))\n",
    "plt.imshow(frame, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "executionInfo": {
     "elapsed": 3054,
     "status": "ok",
     "timestamp": 1620675271367,
     "user": {
      "displayName": "Łukasz Roszkowiak",
      "photoUrl": "",
      "userId": "11129872457337404255"
     },
     "user_tz": -120
    },
    "id": "yRgeQ9KvthWJ",
    "outputId": "02e3de30-75d4-4b30-d2b4-9877e6aa89f8"
   },
   "outputs": [],
   "source": [
    "\n",
    "max_value = 255\n",
    "adaptive_method = cv2.ADAPTIVE_THRESH_GAUSSIAN_C # średniej ważonej \n",
    "threshold_type = cv2.THRESH_BINARY\n",
    "block_size = 11\n",
    "\n",
    "# progowanie z powyższyą wartością progu\n",
    "img_th_adapt = cv2.adaptiveThreshold(img, max_value, adaptive_method, threshold_type, block_size, 5)\n",
    "\n",
    "#cv2_imshow(img_th_binary)\n",
    "frame = cv2.hconcat((img, img_th_adapt))\n",
    "#plt.figure(figsize=(10,10))\n",
    "plt.imshow(frame, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mlICRcyWjSzv"
   },
   "source": [
    "W tym przypadku od użytkownika należy przyjąć wartość rozmiaru okna przetwarania. Uwaga, należy pamiętać, że rozmiar okna przetwarzania powinien być liczbą nieparzystą większą lub równą 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_thresh_adapt(slider_threshold_window):\n",
    "    print(\"Wybrana wielkosc okna: \" + str(slider_threshold_window))\n",
    "    \n",
    "    max_value = 255\n",
    "    adaptive_method = cv2.ADAPTIVE_THRESH_MEAN_C\n",
    "    threshold_type = cv2.THRESH_BINARY\n",
    "    block_size = slider_threshold_window         # wartosc podawana intraktywnie\n",
    "    \n",
    "    # progowanie z powyższyą wartością progu\n",
    "    img_th_adapt = cv2.adaptiveThreshold(img, max_value, adaptive_method, threshold_type, block_size, 5)\n",
    "    \n",
    "    #cv2_imshow(img_th_adapt)\n",
    "    frame = cv2.hconcat((img, img_th_adapt))\n",
    "    #cv2_imshow(frame)\n",
    "    plt.imshow(frame, cmap='gray')\n",
    "    \n",
    "    return slider_threshold_window\n",
    "\n",
    "interact(fun_thresh_adapt, slider_threshold_window=widgets.IntSlider(min=0, max=255, step=1, value=21));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6W6QgZenwVp"
   },
   "source": [
    "## Zad 1. c) Segmentacja obrazu przez progowanie metodą Otsu (Otsu thresholding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ET-0OGzfbdnp"
   },
   "source": [
    "Jest to metoda progowania, oparta na histogramie. Metoda polega na minimalizacji sumy ważonej wariancji dwóch klas (tła i obiektów pierwszego planu), co jest tożsame z maksymalizacją wariancji międzyklasowej. Metodę tę można rozszerzyć do metody wieloprogowej jak również do progowania lokalnego.\n",
    "\n",
    "Często stosuje się najpierw lekkie rozmycie obrazu a dopiero potem progowanie Otsu. Pozwala to m.in. na uniknięcie małych artefaktów.\n",
    "\n",
    "Publikacja: Nobuyuki Otsu, A Threshold Selection Method from Gray-Level Histograms, „IEEE Transactions on Systems, Man, and Cybernetics”, 9 (1), 1979, s. 62–66, DOI: 10.1109/TSMC.1979.4310076"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "executionInfo": {
     "elapsed": 3016,
     "status": "ok",
     "timestamp": 1620675271372,
     "user": {
      "displayName": "Łukasz Roszkowiak",
      "photoUrl": "",
      "userId": "11129872457337404255"
     },
     "user_tz": -120
    },
    "id": "cGzFlRsIbeLi",
    "outputId": "d8f88dd7-c39a-4cea-a68f-9e4df4ad3711"
   },
   "outputs": [],
   "source": [
    "# Otsu's thresholding\n",
    "ret2,th2 = cv2.threshold(img,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "# Otsu's thresholding after Gaussian filtering\n",
    "blur = cv2.GaussianBlur(img,(5,5),0)\n",
    "ret3,th3 = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "\n",
    "frame = cv2.hconcat((th2, th3))\n",
    "#cv2_imshow(frame)\n",
    "plt.imshow(frame, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a6nW3jPWb7S6"
   },
   "source": [
    "# Zadanie 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LiuAvOYkeItF"
   },
   "source": [
    "## Segmentacja obrazu metodą wododziałową (watershed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "re4u-kS4cDdu"
   },
   "source": [
    "Dział wodny (wododział, watershed) to granica pomiędzy zlewiskami różnych rzek\n",
    "lub zbiorników wodnych. Wododziały są zawsze umiejscowione na grzbietach funkcji wysokości terenu. \n",
    "W analizie i przetwarzaniu obrazów pod pojęciem działu wodnego rozumie się operację morfologiczną na obszarze, którego centrum stanowi lokalne minimum w obrazie. Obszary o małej intensywności stanowią w obrazie lokalne „doliny”, zaś obszary o dużej intensywności – lokalne „wzniesienia” . Jako wysokość terenu przyjmuje się amplitudę gradientu intensywności pikseli lub samą\n",
    "intensywność, za wododział zaś – grzbiety tych funkcji.\n",
    "\n",
    "Użycie metody watershed wymaga najpierw wyznaczenia znaczników obszarów które jednoznacznie należą do tła oraz takich które jednoznacznie należą do obiektów. Z pomocą tych obrazów jest wykonywane rozdzielenie obiektów sklejonych, co przedstawiono poniżej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "executionInfo": {
     "elapsed": 2996,
     "status": "ok",
     "timestamp": 1620675271373,
     "user": {
      "displayName": "Łukasz Roszkowiak",
      "photoUrl": "",
      "userId": "11129872457337404255"
     },
     "user_tz": -120
    },
    "id": "eJa44sHuw6qP",
    "outputId": "cf46236a-7b92-4eea-eaa2-6ace55bd4f8f"
   },
   "outputs": [],
   "source": [
    "# Wczytanie obrazu do segmentacji \n",
    "img2 = cv2.imread('water_coins.jpg', cv2.IMREAD_COLOR) # water_coins.jpg\n",
    "#cv2_imshow(img2)\n",
    "plt.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "executionInfo": {
     "elapsed": 2982,
     "status": "ok",
     "timestamp": 1620675271375,
     "user": {
      "displayName": "Łukasz Roszkowiak",
      "photoUrl": "",
      "userId": "11129872457337404255"
     },
     "user_tz": -120
    },
    "id": "GHtsXYnNbMfQ",
    "outputId": "289f5c56-dccc-4b3e-8313-3532b5db4b99"
   },
   "outputs": [],
   "source": [
    "# sprowadzenie obrazu do szaroodcieniowego (grayscale) \n",
    "img_gray = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "# progowanie obrazu czyli wstępne wyznaczenie obiektów\n",
    "ret2,thresh = cv2.threshold(img_gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "\n",
    "#cv2_imshow(thresh)\n",
    "plt.imshow(thresh, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "executionInfo": {
     "elapsed": 2974,
     "status": "ok",
     "timestamp": 1620675271377,
     "user": {
      "displayName": "Łukasz Roszkowiak",
      "photoUrl": "",
      "userId": "11129872457337404255"
     },
     "user_tz": -120
    },
    "id": "63194QHtvpcg",
    "outputId": "074f7e9d-4cf9-4a19-b8c4-293072d30d1b"
   },
   "outputs": [],
   "source": [
    "# odszumianie obrazu przez operacje morfologiczne\n",
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 1)\n",
    "\n",
    "#cv2_imshow(opening)\n",
    "plt.imshow(opening, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "executionInfo": {
     "elapsed": 2965,
     "status": "ok",
     "timestamp": 1620675271380,
     "user": {
      "displayName": "Łukasz Roszkowiak",
      "photoUrl": "",
      "userId": "11129872457337404255"
     },
     "user_tz": -120
    },
    "id": "KjN0AvfOvpTc",
    "outputId": "37bc82da-defa-420a-b584-a556c9052a4c"
   },
   "outputs": [],
   "source": [
    "# wyznaczenie jednoznacznych obszarów tła\n",
    "sure_bg = cv2.dilate(opening,kernel,iterations=1)\n",
    "\n",
    "#cv2_imshow(sure_bg)\n",
    "plt.imshow(sure_bg, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "executionInfo": {
     "elapsed": 2956,
     "status": "ok",
     "timestamp": 1620675271381,
     "user": {
      "displayName": "Łukasz Roszkowiak",
      "photoUrl": "",
      "userId": "11129872457337404255"
     },
     "user_tz": -120
    },
    "id": "gDneSuM2yA6e",
    "outputId": "55fe2f7b-36f4-4f2a-9fc9-61d58bd82a70"
   },
   "outputs": [],
   "source": [
    "# wyznaczenie jednoznacznych obszarów obiektów\n",
    "\n",
    "# krok pośredni: transformata odległościowa\n",
    "dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "print (\"Obraz transformaty odległościwej (pseudokolor dla lepszej wizualizacji)\")\n",
    "#cv2_imshow(cv2.applyColorMap(np.uint8(dist_transform*10), cv2.COLORMAP_JET))\n",
    "plt.imshow(cv2.applyColorMap(np.uint8(dist_transform*10), cv2.COLORMAP_JET))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# określenie jednoznacznych obszarów obiektów przez progowanie obrazu transformaty odlegościowej\n",
    "print (\"Obraz jednoznacznych obszarów należących do obiektów\")\n",
    "ret, sure_fg = cv2.threshold(dist_transform,0.5*dist_transform.max(),255,0)\n",
    "sure_fg = np.uint8(sure_fg)\n",
    "#cv2_imshow(sure_fg)\n",
    "plt.imshow(sure_fg, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "executionInfo": {
     "elapsed": 2946,
     "status": "ok",
     "timestamp": 1620675271384,
     "user": {
      "displayName": "Łukasz Roszkowiak",
      "photoUrl": "",
      "userId": "11129872457337404255"
     },
     "user_tz": -120
    },
    "id": "nl6pfFekvpKq",
    "outputId": "d8375c9b-d9a2-428f-c7ce-f3c9b4c2aae9"
   },
   "outputs": [],
   "source": [
    "# wyznaczenie obszarów \"niepewnych\"  \n",
    "# takich w których znajdują się krawędzie obiektu\n",
    "# obraz uzyskujemy przez odjęcie obszarów jednoznacznych\n",
    "unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "\n",
    "#cv2_imshow(unknown)\n",
    "plt.imshow(unknown, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "executionInfo": {
     "elapsed": 2937,
     "status": "ok",
     "timestamp": 1620675271385,
     "user": {
      "displayName": "Łukasz Roszkowiak",
      "photoUrl": "",
      "userId": "11129872457337404255"
     },
     "user_tz": -120
    },
    "id": "vMKu62y3vo_v",
    "outputId": "254a1f34-3608-437e-eb87-903f770663de"
   },
   "outputs": [],
   "source": [
    "# etykietowanie obiektów\n",
    "ret, markers = cv2.connectedComponents(sure_fg)\n",
    "print(\"Znalezionych obiektów:  \"+str(np.max(markers)))\n",
    "#cv2_imshow(cv2.applyColorMap(np.uint8(markers*10), cv2.COLORMAP_JET))  \n",
    "plt.imshow(cv2.applyColorMap(np.uint8(markers*10), cv2.COLORMAP_JET))\n",
    "#(pseudokolor dla lepszej wizualizacji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "executionInfo": {
     "elapsed": 2926,
     "status": "ok",
     "timestamp": 1620675271387,
     "user": {
      "displayName": "Łukasz Roszkowiak",
      "photoUrl": "",
      "userId": "11129872457337404255"
     },
     "user_tz": -120
    },
    "id": "btdzHE0pwSZX",
    "outputId": "d3b97352-3b3c-413c-c698-89c7090704bf"
   },
   "outputs": [],
   "source": [
    "# dodanie wartości 1 do etykiet, tak aby tło miało wartość 1 a nie 0.\n",
    "markers = markers+1\n",
    "\n",
    "# oznaczenie obszarów \"niepewnych\" jako zero\n",
    "markers[unknown==255] = 0\n",
    "\n",
    "#cv2_imshow(markers)\n",
    "#cv2_imshow(cv2.applyColorMap(np.uint8(markers*10), cv2.COLORMAP_JET)) #(pseudokolor dla lepszej wizualizacji)\n",
    "plt.imshow(cv2.applyColorMap(np.uint8(markers*10), cv2.COLORMAP_JET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "executionInfo": {
     "elapsed": 2917,
     "status": "ok",
     "timestamp": 1620675271388,
     "user": {
      "displayName": "Łukasz Roszkowiak",
      "photoUrl": "",
      "userId": "11129872457337404255"
     },
     "user_tz": -120
    },
    "id": "kFAlwz-ZwSSE",
    "outputId": "e913dcfd-ade8-40a5-c115-77e8d40a0b07"
   },
   "outputs": [],
   "source": [
    "# aplikacj algorytmu wododziału (watershed) do orygnalnego kolorowego obrazu (img2), \n",
    "# dodatkowy argument wymagany do wykonania tej operacji to obliczony powyżej obraz etykietowany\n",
    "markers2 = cv2.watershed(img2, markers)\n",
    "\n",
    "#cv2_imshow(cv2.applyColorMap(np.uint8(markers2*10), cv2.COLORMAP_JET)) #(pseudokolor dla lepszej wizualizacji)\n",
    "plt.imshow(cv2.applyColorMap(np.uint8(markers2*10), cv2.COLORMAP_JET))\n",
    "\n",
    "print(\"Znaleziono \"+ str(np.max(markers2)) + \" obiektów.\")\n",
    "\n",
    "# Wynik:\n",
    "# Granice obiektów zaznaczone w obrazie wartością -1\n",
    "# Obiekty etykietowane kolejnymi wartościami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "executionInfo": {
     "elapsed": 2907,
     "status": "ok",
     "timestamp": 1620675271390,
     "user": {
      "displayName": "Łukasz Roszkowiak",
      "photoUrl": "",
      "userId": "11129872457337404255"
     },
     "user_tz": -120
    },
    "id": "p3iICZHDo1xj",
    "outputId": "50491fc7-2bac-47db-d8ec-034b3cf62e34"
   },
   "outputs": [],
   "source": [
    "# wstawienie linii krawędzi obiektów do obrazu szaroodcieniowego\n",
    "img_gray[markers2 == -1] = 255\n",
    "\n",
    "#cv2_imshow(img_gray)\n",
    "plt.imshow(img_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "executionInfo": {
     "elapsed": 2899,
     "status": "ok",
     "timestamp": 1620675271392,
     "user": {
      "displayName": "Łukasz Roszkowiak",
      "photoUrl": "",
      "userId": "11129872457337404255"
     },
     "user_tz": -120
    },
    "id": "7WWgUqZgwSLT",
    "outputId": "85dbbf29-90a0-46a2-9b4f-8670a0a3f8ca"
   },
   "outputs": [],
   "source": [
    "# wstawienie linii krawędzi obiektów do oryginalnego obrazu kolorowego\n",
    "img2[markers2 == -1] = [255,0,0]\n",
    "\n",
    "#cv2_imshow(img2)\n",
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wizualzacja obiektow (labelling)\n",
    "markers2_colored = cv2.applyColorMap(np.uint8(markers2*10), cv2.COLORMAP_JET)\n",
    "img_blend = cv2.addWeighted(np.stack((img_gray,)*3, axis=-1),0.7,markers2_colored,0.5,-1)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img_blend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RU6PBZBDf6FA"
   },
   "source": [
    "Wynik algorytmu watershed zawarty jest w zmiennej 'markers2'. Jest to obraz odpowiadający rozmiarem obrazowi orygnialnemu w którym oddzielne obiekty są etykietowane (każdy obiekt ma przypisaną jedną wartość) a granice obiektów zaznaczone są wartością -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2891,
     "status": "ok",
     "timestamp": 1620675271394,
     "user": {
      "displayName": "Łukasz Roszkowiak",
      "photoUrl": "",
      "userId": "11129872457337404255"
     },
     "user_tz": -120
    },
    "id": "BuOXZezvqka9"
   },
   "outputs": [],
   "source": [
    "# powyższa procedura zamknięta w jednej funkcji\n",
    "def my_watershed(image):\n",
    "  img_gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "  \n",
    "  ret2,thresh = cv2.threshold(img_gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "  kernel = np.ones((3,3),np.uint8)\n",
    "  opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 1)\n",
    "\n",
    "  sure_bg = cv2.dilate(opening,kernel,iterations=1)\n",
    "  dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "\n",
    "  ret, sure_fg = cv2.threshold(dist_transform,0.5*dist_transform.max(),255,0)\n",
    "  sure_fg = np.uint8(sure_fg)\n",
    "\n",
    "  unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "  ret, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "  markers = markers+1\n",
    "  markers[unknown==255] = 0\n",
    "\n",
    "  markers2 = cv2.watershed(image, markers)\n",
    "\n",
    "  img_gray[markers2 == -1] = 255\n",
    "  image[markers2 == -1] = [255,0,0]\n",
    "\n",
    "  print(\"Znaleziono \"+ str(np.max(markers2)) + \" obiektów.\")\n",
    "\n",
    "  # wizuaizacja: obraz oryginalny oraz wynik algorytmy watershed\n",
    "  frame = cv2.hconcat(( image, cv2.applyColorMap(np.uint8(markers2*10), cv2.COLORMAP_JET) ))\n",
    "  #cv2_imshow(frame)\n",
    "  plt.imshow(frame)\n",
    "\n",
    "  return markers2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 353
    },
    "executionInfo": {
     "elapsed": 2880,
     "status": "error",
     "timestamp": 1620675271396,
     "user": {
      "displayName": "Łukasz Roszkowiak",
      "photoUrl": "",
      "userId": "11129872457337404255"
     },
     "user_tz": -120
    },
    "id": "p_v7MuIjkWkW",
    "outputId": "558b45e2-4ac6-4803-9123-7dd6dc9785b1"
   },
   "outputs": [],
   "source": [
    "# Dodatkowe przykłady\n",
    "out1 = my_watershed(cv2.imread('soczewica2.jpg', cv2.IMREAD_COLOR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = my_watershed(cv2.imread('ryz1.jpg', cv2.IMREAD_COLOR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQTN1SmTpe8d"
   },
   "source": [
    "Jak widać na powyższych przykładach algorytm watershed nie jest idealny. Obiekty które nachodzą na siebie w większym stopniu niż stykanie się są trudne do rozdzielenia tą metodą. Ponadto, klastry zawierające dużą liczbę obietków również stanowią problem. Algorytm mylnie rozpoznaje granice lub nie rozdziela obiektów na pojedyncze."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNcQhG/sp0PFUFBs56qLiWb",
   "collapsed_sections": [],
   "name": "APO_Lab5_Segmentacja.ipynb",
   "provenance": [
    {
     "file_id": "1IoWt71ba0mAldqNrRSQDYARk6SVzbln3",
     "timestamp": 1587366409708
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
